{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Long_Attention_Image_captioning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRj_AN09r_-E"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.vgg16 import  VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "import warnings\n",
        "import os\n",
        "import pickle\n",
        "import time\n",
        "import json\n",
        "import cv2\n",
        "import re\n",
        "import string\n",
        "import unicodedata\n",
        "from sklearn.utils import shuffle\n",
        "from tqdm import tqdm\n",
        "warnings.filterwarnings(action = \"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27dmvSSasC0r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "766d3925-bb4f-4967-ee98-b9e4d3d7369b"
      },
      "source": [
        "annotation_folder = '/annotations/'\n",
        "if not os.path.exists(os.path.abspath('.') + annotation_folder):\n",
        "  annotation_zip = tf.keras.utils.get_file('captions.zip',\n",
        "                                          cache_subdir=os.path.abspath('.'),\n",
        "                                          origin = \"https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip\",\n",
        "                                          extract = True)\n",
        "  os.remove(annotation_zip)\n",
        "\n",
        "image_folder = '/train2014/'\n",
        "if not os.path.exists(os.path.abspath('.') + image_folder):\n",
        "  image_zip = tf.keras.utils.get_file('train2014.zip',\n",
        "                                      cache_subdir=os.path.abspath('.'),\n",
        "                                      origin = \"https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip\",\n",
        "                                      extract = True)\n",
        "  os.remove(image_zip)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip\n",
            "2342912/2340801 [==============================] - 0s 0us/step\n",
            "Downloading data from https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip\n",
            "1115422720/1115419746 [==============================] - 24s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adqm5bFIsExT"
      },
      "source": [
        "text_path = \"/content/Flickr8k.token.txt\"\n",
        "images_path = \"/content/Flicker8k_Dataset\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh-GfYAQsGuT"
      },
      "source": [
        "text = \"\"\n",
        "with open(text_path) as file:\n",
        "  text = file.read()\n",
        "\n",
        "def load_descriptions(doc):\n",
        "\tmapping = dict()\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\ttokens = line.split()\n",
        "\t\tif len(line) < 2:\n",
        "\t\t\tcontinue\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\timage_id = image_id.split('.')[0]\n",
        "\t\timage_desc = ' '.join(image_desc)\n",
        "\t\tif image_id not in mapping:\n",
        "\t\t\tmapping[image_id] = list()\n",
        "\t\tmapping[image_id].append(image_desc)\n",
        "\treturn mapping\n",
        "\n",
        "image_captions = load_descriptions(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-KWd6wVsIeS"
      },
      "source": [
        "def clean(lang):\n",
        "    pattern_ = re.compile('[^%s]' % re.escape(string.printable))\n",
        "    table = str.maketrans('','',string.punctuation)\n",
        "    lang = unicodedata.normalize('NFD',lang).encode('ascii','ignore').decode('UTF-8')\n",
        "    lang = lang.split()\n",
        "    lang = [pattern_.sub('',word) for word in lang]\n",
        "    lang = [word.lower() for word in lang]\n",
        "    lang = [word.translate(table) for word in lang]\n",
        "    lang = [word for word in lang if word.isalpha()]\n",
        "    return ' '.join(lang)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYc_kfexsLAT"
      },
      "source": [
        "for item in image_captions:\n",
        "  for i,lines in enumerate(image_captions[item]):\n",
        "    image_captions[item][i] = clean(lines)      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsoxZLtxsLdK"
      },
      "source": [
        "for key in image_captions.keys():\n",
        "  image_captions[key] = '<start> ' + image_captions[key][0] + ' <end>'  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xngTeI63sLfp"
      },
      "source": [
        "# here i have not normalized the images cause i ran out of memory\n",
        "vectors = {}\n",
        "for image_names in os.listdir(images_path):\n",
        "  image_id = image_names.split('.')[0]\n",
        "  path = os.path.join(images_path,image_id + str(\".jpg\"))\n",
        "  image = cv2.imread(path)\n",
        "  image = cv2.resize(image,(224,224))\n",
        "  image = np.asarray(image)\n",
        "  try:\n",
        "    vectors[image_id] = image\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS8McXuisPGr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "outputId": "fa2aee31-6edd-49aa-801a-ac83279adb5c"
      },
      "source": [
        "cnn_model  = VGG16(include_top = False , weights=\"imagenet\" )\n",
        "cnn_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, None, None, 3)]   0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0AZDNAZsQla"
      },
      "source": [
        "for key in vectors.keys():\n",
        "  vectors[key] = cnn_model(np.expand_dims(vectors[key],0))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTTArZ5dsVir"
      },
      "source": [
        "for key in vectors.keys():\n",
        "  vectors[key] = np.reshape(vectors[key],(1,49,512))\n",
        "filename = 'image_vectors'\n",
        "outfile = open(filename,'wb')\n",
        "pickle.dump(vectors,outfile)\n",
        "outfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_1iWpcXsWYq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "2f292d64-c6dd-49ae-a830-fab84de107b7"
      },
      "source": [
        "input_tensor = []\n",
        "target_tensor = []\n",
        "for key in vectors.keys():\n",
        "  if image_captions.get(key,None) is not None:\n",
        "    target_tensor.append(image_captions.get(key))\n",
        "    input_tensor.append(vectors[key])\n",
        "  else:\n",
        "    continue  \n",
        "input_tensor = tf.concat(input_tensor,axis = 0)\n",
        "target_tensor[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<start> a group of college students walk in nice weather <end>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yHhQJWRsh4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "9174e5f6-22a0-4347-dc74-2b5349ba7e8c"
      },
      "source": [
        "source_sentence_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "source_sentence_tokenizer.fit_on_texts(target_tensor)\n",
        "source_tensor = source_sentence_tokenizer.texts_to_sequences(target_tensor)\n",
        "source_tensor= tf.keras.preprocessing.sequence.pad_sequences(source_tensor,padding='post' )\n",
        "print(\"Max len of caption : \"  + str(len(source_tensor[0])))\n",
        "print(\"Source/Target shape : \" + str(len(source_tensor)))\n",
        "print(\"Source/Target shape : \",source_tensor.shape)\n",
        "print(\"Shape input tensor : \",input_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max len of caption : 35\n",
            "Source/Target shape : 8091\n",
            "Source/Target shape :  (8091, 35)\n",
            "Shape input tensor :  (8091, 49, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I0y6RItsima",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b8c1ea0d-d04e-4834-f19d-e09d12aea08d"
      },
      "source": [
        "BATCH_SIZE = 100\n",
        "embedding_dim = 256\n",
        "vocab_size = len(source_sentence_tokenizer.word_index) + 1\n",
        "units = 512\n",
        "num_steps = len(input_tensor) // BATCH_SIZE\n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (input_tensor,source_tensor))\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "print(\"Vocab size is : \",vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size is :  4481\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzEtq_1oLJ8c"
      },
      "source": [
        "# This encoder is for Neural Machine Translation and other purposes\n",
        "class Encoder(tf.keras.Model):\n",
        "\n",
        "  def __init__(self,dim,units,vocab_size):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.dim = dim\n",
        "    self.units = units\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,self.dim)\n",
        "    self.LSTM = tf.keras.layers.LSTM(self.units,return_sequences = True, return_state = True, recurrent_initializer='glorot_uniform') \n",
        "\n",
        "    def call(self,x,hidden):\n",
        "\n",
        "      x = self.embeddding(x)\n",
        "      x = self.LSTM(x,hiddden)  \n",
        "      return x\n",
        "\n",
        "\n",
        "  def init_hidden(self,batch):\n",
        "     return (tf.zeros([batch,self.units]),tf.zeros([batch,self.units]))  \n",
        "\n",
        "\n",
        "class CNN_Encoder(tf.keras.Model):\n",
        "    # Since you have already extracted the features and dumped it using pickle\n",
        "    # This encoder passes those features through a Fully connected layer\n",
        "\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(CNN_Encoder, self).__init__()\n",
        "        # shape after fc == (batch_size, 64, embedding_dim)\n",
        "        self.fc = tf.keras.layers.Dense(embedding_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class LoungAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self,units):\n",
        "     super(LoungAttention,self).__init__()\n",
        "     self.units = units\n",
        "     self.ws = tf.keras.layers.Dense(self.units) \n",
        "     self.wc = tf.keras.layers.Dense(self.units) \n",
        "  \n",
        "  def call(self,hidden,encoder_output):\n",
        "\n",
        "    hidden = tf.expand_dims(hidden,axis = 1)\n",
        "    score  = tf.matmul(hidden,self.ws(encoder_output),transpose_b = True)\n",
        "    score = tf.nn.softmax(score,axis = 2)\n",
        "    attention = tf.matmul(score,self.wc(encoder_output))\n",
        "    return tf.squeeze(attention,axis = 1)\n",
        "   \n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "\n",
        "  def __init__(self,dim,units,vocab_size):\n",
        "      super(Decoder,self).__init__()\n",
        "      self.dim = dim\n",
        "      self.units = units\n",
        "      self.vocab_size = vocab_size\n",
        "      self.embedding = tf.keras.layers.Embedding(self.vocab_size,self.dim)\n",
        "      self.LSTM = tf.keras.layers.LSTM(self.units,return_sequences = True, return_state = True, recurrent_initializer='glorot_uniform') \n",
        "      self.attention_layer = LoungAttention(self.units)\n",
        "      self.wc = tf.keras.layers.Dense(self.units, activation='tanh')\n",
        "      self.ws = tf.keras.layers.Dense(self.vocab_size)\n",
        "\n",
        "  def call(self,x,hidden,encoder_output):\n",
        "\n",
        "    x = self.embedding(x)\n",
        "    lstm_out, state_h, state_c = self.LSTM(x, initial_state = hidden)\n",
        "  \n",
        "    context_vector = self.attention_layer(state_h,encoder_output) # batch,units\n",
        "    output = tf.concat([tf.squeeze(lstm_out,axis = 1),context_vector],axis = -1)\n",
        "    output = self.wc(output)\n",
        "    output = self.ws(output)\n",
        "    return output,state_h,state_c\n",
        "\n",
        "  def reset_state(self,batch):\n",
        "    return (tf.zeros([batch,self.units]),tf.zeros([batch,self.units]))  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaLFeZP6pkVs"
      },
      "source": [
        "encoder = CNN_Encoder(embedding_dim)\n",
        "decoder = Decoder(embedding_dim, units, vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAEGIe8GUydx"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc0oUgfHsuXa"
      },
      "source": [
        "@tf.function\n",
        "def train_step(img_tensor, target):\n",
        "  loss = 0\n",
        "  hidden = decoder.reset_state(batch = target.shape[0])\n",
        "  decoder_input = tf.expand_dims([source_sentence_tokenizer.word_index['<start>']] * target.shape[0], 1)\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "      encoder_output = encoder(img_tensor)\n",
        "\n",
        "      for i in range(1, target.shape[1]):\n",
        "          decoder_output = decoder(decoder_input,hidden,encoder_output)\n",
        "          hidden = decoder_output[1:]\n",
        "          loss += loss_function(target[:, i], decoder_output[0])\n",
        "          decoder_input = tf.expand_dims(target[:, i], 1)\n",
        "\n",
        "  total_loss = (loss / int(target.shape[1]))\n",
        "  trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "\n",
        "  return loss, total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DDcnUW1yvTw"
      },
      "source": [
        "checkpoint_path = \"./checkpoints/train\"\n",
        "ckpt = tf.train.Checkpoint(encoder=encoder,\n",
        "                           decoder=decoder,\n",
        "                           optimizer = optimizer)\n",
        "c/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGU5Lk5HswQs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7bb8ebbf-f99a-46fa-89b4-26c6bc179d92"
      },
      "source": [
        "\"\"\"EPOCHS = 100\n",
        "loss_plot = []\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (img_tensor, target)) in enumerate(dataset.take(-1)):\n",
        "        batch_loss, t_loss = train_step(img_tensor, target)\n",
        "        total_loss += t_loss\n",
        "\n",
        "    loss_plot.append(total_loss / num_steps)\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "      ckpt_manager.save()\n",
        "\n",
        "    print ('Epoch {} Loss {:.6f}'.format(epoch + 1,\n",
        "                                         total_loss/num_steps))\n",
        "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 1.755620\n",
            "Time taken for 1 epoch 12.623716831207275 sec\n",
            "\n",
            "Epoch 2 Loss 1.708492\n",
            "Time taken for 1 epoch 12.48074221611023 sec\n",
            "\n",
            "Epoch 3 Loss 1.681631\n",
            "Time taken for 1 epoch 12.469922542572021 sec\n",
            "\n",
            "Epoch 4 Loss 1.641180\n",
            "Time taken for 1 epoch 12.45289158821106 sec\n",
            "\n",
            "Epoch 5 Loss 1.570204\n",
            "Time taken for 1 epoch 12.476596355438232 sec\n",
            "\n",
            "Epoch 6 Loss 1.480142\n",
            "Time taken for 1 epoch 12.584820985794067 sec\n",
            "\n",
            "Epoch 7 Loss 1.386377\n",
            "Time taken for 1 epoch 12.479850769042969 sec\n",
            "\n",
            "Epoch 8 Loss 1.306499\n",
            "Time taken for 1 epoch 12.54543924331665 sec\n",
            "\n",
            "Epoch 9 Loss 1.249379\n",
            "Time taken for 1 epoch 12.479151487350464 sec\n",
            "\n",
            "Epoch 10 Loss 1.212836\n",
            "Time taken for 1 epoch 12.382791996002197 sec\n",
            "\n",
            "Epoch 11 Loss 1.173516\n",
            "Time taken for 1 epoch 12.566399574279785 sec\n",
            "\n",
            "Epoch 12 Loss 1.135935\n",
            "Time taken for 1 epoch 12.430074453353882 sec\n",
            "\n",
            "Epoch 13 Loss 1.105762\n",
            "Time taken for 1 epoch 12.391925573348999 sec\n",
            "\n",
            "Epoch 14 Loss 1.076325\n",
            "Time taken for 1 epoch 12.442643165588379 sec\n",
            "\n",
            "Epoch 15 Loss 1.056599\n",
            "Time taken for 1 epoch 12.403953790664673 sec\n",
            "\n",
            "Epoch 16 Loss 1.033505\n",
            "Time taken for 1 epoch 12.497199773788452 sec\n",
            "\n",
            "Epoch 17 Loss 0.995017\n",
            "Time taken for 1 epoch 12.394300699234009 sec\n",
            "\n",
            "Epoch 18 Loss 0.962415\n",
            "Time taken for 1 epoch 12.440695524215698 sec\n",
            "\n",
            "Epoch 19 Loss 0.932204\n",
            "Time taken for 1 epoch 12.399621725082397 sec\n",
            "\n",
            "Epoch 20 Loss 0.922686\n",
            "Time taken for 1 epoch 12.393928527832031 sec\n",
            "\n",
            "Epoch 21 Loss 0.923775\n",
            "Time taken for 1 epoch 12.524903774261475 sec\n",
            "\n",
            "Epoch 22 Loss 0.915179\n",
            "Time taken for 1 epoch 12.399444818496704 sec\n",
            "\n",
            "Epoch 24 Loss 0.895085\n",
            "Time taken for 1 epoch 12.375447273254395 sec\n",
            "\n",
            "Epoch 25 Loss 0.882340\n",
            "Time taken for 1 epoch 12.397867918014526 sec\n",
            "\n",
            "Epoch 26 Loss 0.853494\n",
            "Time taken for 1 epoch 12.559524059295654 sec\n",
            "\n",
            "Epoch 27 Loss 0.843172\n",
            "Time taken for 1 epoch 12.421055316925049 sec\n",
            "\n",
            "Epoch 28 Loss 0.826218\n",
            "Time taken for 1 epoch 12.432751893997192 sec\n",
            "\n",
            "Epoch 29 Loss 0.851808\n",
            "Time taken for 1 epoch 12.388028621673584 sec\n",
            "\n",
            "Epoch 30 Loss 0.819958\n",
            "Time taken for 1 epoch 12.410266160964966 sec\n",
            "\n",
            "Epoch 31 Loss 0.800417\n",
            "Time taken for 1 epoch 12.502799034118652 sec\n",
            "\n",
            "Epoch 32 Loss 0.791109\n",
            "Time taken for 1 epoch 12.353082656860352 sec\n",
            "\n",
            "Epoch 33 Loss 0.786080\n",
            "Time taken for 1 epoch 12.437384843826294 sec\n",
            "\n",
            "Epoch 34 Loss 0.775091\n",
            "Time taken for 1 epoch 12.419068574905396 sec\n",
            "\n",
            "Epoch 35 Loss 0.761332\n",
            "Time taken for 1 epoch 12.340086460113525 sec\n",
            "\n",
            "Epoch 36 Loss 0.735997\n",
            "Time taken for 1 epoch 12.519315719604492 sec\n",
            "\n",
            "Epoch 37 Loss 0.718859\n",
            "Time taken for 1 epoch 12.348480701446533 sec\n",
            "\n",
            "Epoch 38 Loss 0.698330\n",
            "Time taken for 1 epoch 12.373747825622559 sec\n",
            "\n",
            "Epoch 39 Loss 0.697314\n",
            "Time taken for 1 epoch 12.361465454101562 sec\n",
            "\n",
            "Epoch 40 Loss 0.687010\n",
            "Time taken for 1 epoch 12.351471900939941 sec\n",
            "\n",
            "Epoch 41 Loss 0.673824\n",
            "Time taken for 1 epoch 12.513083219528198 sec\n",
            "\n",
            "Epoch 42 Loss 0.656424\n",
            "Time taken for 1 epoch 12.392780303955078 sec\n",
            "\n",
            "Epoch 43 Loss 0.648246\n",
            "Time taken for 1 epoch 12.366058588027954 sec\n",
            "\n",
            "Epoch 44 Loss 0.633116\n",
            "Time taken for 1 epoch 12.31785249710083 sec\n",
            "\n",
            "Epoch 45 Loss 0.646909\n",
            "Time taken for 1 epoch 12.355693578720093 sec\n",
            "\n",
            "Epoch 46 Loss 0.637358\n",
            "Time taken for 1 epoch 12.459347009658813 sec\n",
            "\n",
            "Epoch 47 Loss 0.642950\n",
            "Time taken for 1 epoch 12.341588258743286 sec\n",
            "\n",
            "Epoch 48 Loss 0.627896\n",
            "Time taken for 1 epoch 12.324491739273071 sec\n",
            "\n",
            "Epoch 49 Loss 0.617834\n",
            "Time taken for 1 epoch 12.33961820602417 sec\n",
            "\n",
            "Epoch 50 Loss 0.629953\n",
            "Time taken for 1 epoch 12.320672988891602 sec\n",
            "\n",
            "Epoch 51 Loss 0.641723\n",
            "Time taken for 1 epoch 12.438726425170898 sec\n",
            "\n",
            "Epoch 52 Loss 0.625604\n",
            "Time taken for 1 epoch 12.288597106933594 sec\n",
            "\n",
            "Epoch 53 Loss 0.618807\n",
            "Time taken for 1 epoch 12.305505752563477 sec\n",
            "\n",
            "Epoch 54 Loss 0.600916\n",
            "Time taken for 1 epoch 12.3407564163208 sec\n",
            "\n",
            "Epoch 55 Loss 0.598470\n",
            "Time taken for 1 epoch 12.301328182220459 sec\n",
            "\n",
            "Epoch 56 Loss 0.602412\n",
            "Time taken for 1 epoch 12.449899673461914 sec\n",
            "\n",
            "Epoch 57 Loss 0.587589\n",
            "Time taken for 1 epoch 12.3307204246521 sec\n",
            "\n",
            "Epoch 58 Loss 0.617581\n",
            "Time taken for 1 epoch 12.43798279762268 sec\n",
            "\n",
            "Epoch 59 Loss 0.618791\n",
            "Time taken for 1 epoch 12.348191022872925 sec\n",
            "\n",
            "Epoch 60 Loss 0.596036\n",
            "Time taken for 1 epoch 12.339511394500732 sec\n",
            "\n",
            "Epoch 61 Loss 0.572460\n",
            "Time taken for 1 epoch 12.451493501663208 sec\n",
            "\n",
            "Epoch 62 Loss 0.577109\n",
            "Time taken for 1 epoch 12.314225673675537 sec\n",
            "\n",
            "Epoch 63 Loss 0.566308\n",
            "Time taken for 1 epoch 12.301540613174438 sec\n",
            "\n",
            "Epoch 64 Loss 0.579673\n",
            "Time taken for 1 epoch 12.286701679229736 sec\n",
            "\n",
            "Epoch 65 Loss 0.578925\n",
            "Time taken for 1 epoch 12.271943092346191 sec\n",
            "\n",
            "Epoch 66 Loss 0.577261\n",
            "Time taken for 1 epoch 12.404613494873047 sec\n",
            "\n",
            "Epoch 67 Loss 0.551289\n",
            "Time taken for 1 epoch 12.318730354309082 sec\n",
            "\n",
            "Epoch 68 Loss 0.598628\n",
            "Time taken for 1 epoch 12.312337875366211 sec\n",
            "\n",
            "Epoch 69 Loss 0.584540\n",
            "Time taken for 1 epoch 12.302355289459229 sec\n",
            "\n",
            "Epoch 70 Loss 0.546293\n",
            "Time taken for 1 epoch 12.322885990142822 sec\n",
            "\n",
            "Epoch 71 Loss 0.516255\n",
            "Time taken for 1 epoch 12.42516541481018 sec\n",
            "\n",
            "Epoch 72 Loss 0.498052\n",
            "Time taken for 1 epoch 12.339813709259033 sec\n",
            "\n",
            "Epoch 73 Loss 0.496964\n",
            "Time taken for 1 epoch 12.315925598144531 sec\n",
            "\n",
            "Epoch 74 Loss 0.490345\n",
            "Time taken for 1 epoch 12.30185580253601 sec\n",
            "\n",
            "Epoch 75 Loss 0.501286\n",
            "Time taken for 1 epoch 12.292506694793701 sec\n",
            "\n",
            "Epoch 76 Loss 0.518696\n",
            "Time taken for 1 epoch 12.409923791885376 sec\n",
            "\n",
            "Epoch 77 Loss 0.542273\n",
            "Time taken for 1 epoch 12.321000576019287 sec\n",
            "\n",
            "Epoch 78 Loss 0.532400\n",
            "Time taken for 1 epoch 12.29356575012207 sec\n",
            "\n",
            "Epoch 79 Loss 0.515706\n",
            "Time taken for 1 epoch 12.335755348205566 sec\n",
            "\n",
            "Epoch 80 Loss 0.498347\n",
            "Time taken for 1 epoch 12.30434274673462 sec\n",
            "\n",
            "Epoch 81 Loss 0.522717\n",
            "Time taken for 1 epoch 12.41684341430664 sec\n",
            "\n",
            "Epoch 82 Loss 0.531364\n",
            "Time taken for 1 epoch 12.328231573104858 sec\n",
            "\n",
            "Epoch 83 Loss 0.517509\n",
            "Time taken for 1 epoch 12.348749160766602 sec\n",
            "\n",
            "Epoch 84 Loss 0.511276\n",
            "Time taken for 1 epoch 12.290134191513062 sec\n",
            "\n",
            "Epoch 85 Loss 0.533391\n",
            "Time taken for 1 epoch 12.296407461166382 sec\n",
            "\n",
            "Epoch 86 Loss 0.525430\n",
            "Time taken for 1 epoch 12.407671451568604 sec\n",
            "\n",
            "Epoch 87 Loss 0.509988\n",
            "Time taken for 1 epoch 12.306133031845093 sec\n",
            "\n",
            "Epoch 88 Loss 0.498328\n",
            "Time taken for 1 epoch 12.257277727127075 sec\n",
            "\n",
            "Epoch 89 Loss 0.501444\n",
            "Time taken for 1 epoch 12.244408130645752 sec\n",
            "\n",
            "Epoch 90 Loss 0.504728\n",
            "Time taken for 1 epoch 12.256011724472046 sec\n",
            "\n",
            "Epoch 91 Loss 0.518257\n",
            "Time taken for 1 epoch 12.345856666564941 sec\n",
            "\n",
            "Epoch 92 Loss 0.524816\n",
            "Time taken for 1 epoch 12.323119640350342 sec\n",
            "\n",
            "Epoch 93 Loss 0.531218\n",
            "Time taken for 1 epoch 12.289631128311157 sec\n",
            "\n",
            "Epoch 94 Loss 0.556322\n",
            "Time taken for 1 epoch 12.243041276931763 sec\n",
            "\n",
            "Epoch 95 Loss 0.529409\n",
            "Time taken for 1 epoch 12.284076452255249 sec\n",
            "\n",
            "Epoch 96 Loss 0.503137\n",
            "Time taken for 1 epoch 12.377111911773682 sec\n",
            "\n",
            "Epoch 97 Loss 0.505171\n",
            "Time taken for 1 epoch 12.257174730300903 sec\n",
            "\n",
            "Epoch 98 Loss 0.523455\n",
            "Time taken for 1 epoch 12.231595754623413 sec\n",
            "\n",
            "Epoch 99 Loss 0.528837\n",
            "Time taken for 1 epoch 12.267361879348755 sec\n",
            "\n",
            "Epoch 100 Loss 0.498514\n",
            "Time taken for 1 epoch 12.29877233505249 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk1OB5kCvg-Q"
      },
      "source": [
        "encoder.save_weights('encoder_Loung.h5')\n",
        "decoder.save_weights('decoder_Loung.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3VJTcYbvMof",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "46f0f7be-9283-4700-c4c4-d6fcd0c60f41"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(np.arange(1,EPOCHS+1,1),loss_plot)\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkb8kZDE6uo2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}